---
title: "The Mission"
description: ""
lead: ""
date: 2020-10-13T15:21:01+02:00
lastmod: 2020-10-13T15:21:01+02:00
draft: false
images: []
menu:
  docs:
    parent: "about"
weight: 100
toc: true
---
Large Language Models (LLMs) are fast becoming an essential tool for all fields of AI research. One striking feature of these large pre-trained models is that they can be adapted to a wide variety of language tasks, often with very little in-domain data. In recent years, the development of LLMs have mostly been led by highly capitalized industry labs, leaving academia and smaller labs dependent on what these corporations share with the broader research community. 

Given the increasing impact of LLMs on society, we believe it is vital to develop these powerful tools with responsible AI principles. Specifically, Big Code values (1) inclusivity by welcoming contributions from all AI researchers and (2) openness and transparency regarding the LLM development process, including discussions about data sources, data rights, and their legal and ethical concerns. To foster open collaboration across institutes and corporations, we've put significant effort into setting up a clear and transparent governance structure. See, for example, [how we manage intellectual property]({{< relref "docs/about/ip.md" >}}). 

Big Code is inspired by the [Big Science project](https://bigscience.huggingface.co/), an open scientific collaboration which culminated in July 2022 with the release of the [World’s Largest Open Multilingual Language Model](https://huggingface.co/bigscience/bloom). One key difference is that Big Code is focused on developing LLMs for code applications. Such models enable the completion and synthesis of code, both from other code and natural language descriptions, and can work across a wide range of domains, tasks, and programming languages. 






<!-- However, it is increasingly difficult for academia and smaller industry labs to develop such models due to their high training cost and large engineering efforts. To democratize the training of LLMs, the [Big Science project](https://bigscience.huggingface.co/) was launched in May 2021 and their year-long program culminated with the release of the [World’s Largest Open Multilingual Language Model](https://huggingface.co/bigscience/bloom). 

Building on this success, we introduce Big Code: an open-scientific collaboration focused on LLMs for code. The purpose of the Big Code project is to collaboratively work towards exploring, training, releasing LLMs for code. To this end, the collaboration [actively seeks contributions from AI practitioners](/docs/about/join) who are interested in the following research topics:
- Curating training datasets for code LLMs
- Distributed training methods for LLMs
- Developing a representative evaluation suite for code LLMs (i.e., covering multiple tasks and programming languages)
- Developing methods for faster training and inference of LLMs
- Discussing the legal aspects of Code LLMs -->